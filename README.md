

# ğŸ¤– Termux AI Pro

### **The Ultimate CLI AI Client for Termux**

> Chat with GPT-4, Gemini, DeepSeek, and Local Models â€” all inside a beautiful, rich terminal interface.

Termux AI Pro is a full-featured Python application designed to replace basic shell scripts.
It brings a modern AI chat experience to Termux with **Markdown rendering**, **streaming responses**, and **multi-provider support**.

---

## âœ¨ Features

### ğŸ¨ Beautiful UI

Powered by the **Rich** library â€” supports Markdown, code blocks, tables, lists, and more.

### âš¡ Real-time Streaming

Responses appear instantly as the AI types.

### ğŸŒ Universal Model Support

Out of the box integration with:

* **OpenRouter** (DeepSeek, Claude 3, Llama 3, etc.)
* **Google Gemini** (Free tier available)
* **OpenAI** (GPT-4o, GPT-3.5)
* **Local / Ollama** (Run on your PC or local server)

### ğŸ’¾ Session Memory

The AI remembers earlier messages within the current conversation.

### âš™ï¸ Easy Configuration

Includes a settings menu to manage API keys, models, and providers â€” no file editing needed.

---

## ğŸš€ Installation

---

### **Option 1 â€” Standard Clone & Install (Recommended)**

Install Git & Python:

```bash
pkg update && pkg upgrade -y
pkg install git python -y
```

Clone your repository:

```bash
git clone https://github.com/YOUR_USERNAME/Termux-AI-Pro.git
cd Termux-AI-Pro
```

Run installer:

```bash
chmod +x install.sh
./install.sh
```

---

### **Option 2 â€” One-Line Installer**

Run directly from Termux:

```bash
curl -sL https://raw.githubusercontent.com/nyxulll/Termux-AI-Pro/main/install.sh | bash
```

---

## ğŸ® Usage

Launch the AI from anywhere:

```bash
termux-ai
```

### **In-Chat Commands**

| Command           | Description               |
| ----------------- | ------------------------- |
| `menu`            | Open settings menu        |
| `clear`           | Clear conversation memory |
| `exit`            | Quit application          |
| *(anything else)* | Send message to AI        |

---

## ğŸ”‘ Setup & Configuration

The first run will prompt you to enter your API key.

### **Where to Get API Keys**

* **OpenRouter** â€” Free + paid (recommended)
* **Google AI Studio** â€” Free Gemini keys
* **OpenAI Platform** â€” Paid

### **To Enter Your Key**

1. Run `termux-ai`
2. Type `menu`
3. Select **[2] Edit Configuration**
4. Choose provider (OpenRouter, Gemini, etc.)
5. Paste your API key

---

## ğŸ  Using Local AI (Ollama)

You can connect Termux to an **Ollama server** running on your PC.

### **Step 1 â€” Make Ollama Network-Accessible**

On your PC:

```bash
export OLLAMA_HOST=0.0.0.0
```

### **Step 2 â€” Configure Termux AI**

1. Run `termux-ai`
2. Type `menu`
3. Select **[1] Switch Provider â†’ Local (Ollama)**
4. Go to **[2] Edit Configuration**
5. Set Base URL:

```
http://YOUR_PC_IP_ADDRESS:11434/v1
```

6. Set Model to your installed model (e.g., `llama3`)

---

## ğŸ› ï¸ Troubleshooting

### **âŒ â€œCommand not foundâ€**

Run:

```bash
hash -r
```

Or restart Termux.

### **âŒ Connection Errors**

* Check your API key in the menu
* Ensure internet is working
* If using remote models, verify credit/access
* For Ollama, ensure the server is reachable on your network

### **Config File Location**

```
~/.config/termux_ai_pro/config.json
```

---

## ğŸ“ License

This project is licensed under the **MIT License** . MADE WITH â¤ï¸ FOR THE termux COMMUNITY.

