

# ü§ñ Termux AI Pro

### **The Ultimate CLI AI Client for Termux**

> Chat with GPT-4, Gemini, DeepSeek, and Local Models ‚Äî all inside a beautiful, rich terminal interface.

Termux AI Pro is a full-featured Python application designed to replace basic shell scripts.
It brings a modern AI chat experience to Termux with **Markdown rendering**, **streaming responses**, and **multi-provider support**.

---

## ‚ú® Features

### üé® Beautiful UI

Powered by the **Rich** library ‚Äî supports Markdown, code blocks, tables, lists, and more.

### ‚ö° Real-time Streaming

Responses appear instantly as the AI types.

### üåç Universal Model Support

Out of the box integration with:

* **OpenRouter** (DeepSeek, Claude 3, Llama 3, etc.)
* **Google Gemini** (Free tier available)
* **OpenAI** (GPT-4o, GPT-3.5)
* **Local / Ollama** (Run on your PC or local server)

### üíæ Session Memory

The AI remembers earlier messages within the current conversation.

### ‚öôÔ∏è Easy Configuration

Includes a settings menu to manage API keys, models, and providers ‚Äî no file editing needed.

---

## üöÄ Installation

> ‚ö†Ô∏è **IMPORTANT:**
> Replace **`YOUR_USERNAME`** and **`Termux-AI-Pro`** with your actual GitHub username and repository name.

---

### **Option 1 ‚Äî Standard Clone & Install (Recommended)**

Install Git & Python:

```bash
pkg update && pkg upgrade -y
pkg install git python -y
```

Clone your repository:

```bash
git clone https://github.com/YOUR_USERNAME/Termux-AI-Pro.git
cd Termux-AI-Pro
```

Run installer:

```bash
chmod +x install.sh
./install.sh
```

---

### **Option 2 ‚Äî One-Line Installer**

Run directly from Termux:

```bash
curl -sL https://raw.githubusercontent.com/YOUR_USERNAME/Termux-AI-Pro/main/install.sh | bash
```

---

## üéÆ Usage

Launch the AI from anywhere:

```bash
termux-ai
```

### **In-Chat Commands**

| Command           | Description               |
| ----------------- | ------------------------- |
| `menu`            | Open settings menu        |
| `clear`           | Clear conversation memory |
| `exit`            | Quit application          |
| *(anything else)* | Send message to AI        |

---

## üîë Setup & Configuration

The first run will prompt you to enter your API key.

### **Where to Get API Keys**

* **OpenRouter** ‚Äî Free + paid (recommended)
* **Google AI Studio** ‚Äî Free Gemini keys
* **OpenAI Platform** ‚Äî Paid

### **To Enter Your Key**

1. Run `termux-ai`
2. Type `menu`
3. Select **[2] Edit Configuration**
4. Choose provider (OpenRouter, Gemini, etc.)
5. Paste your API key

---

## üè† Using Local AI (Ollama)

You can connect Termux to an **Ollama server** running on your PC.

### **Step 1 ‚Äî Make Ollama Network-Accessible**

On your PC:

```bash
export OLLAMA_HOST=0.0.0.0
```

### **Step 2 ‚Äî Configure Termux AI**

1. Run `termux-ai`
2. Type `menu`
3. Select **[1] Switch Provider ‚Üí Local (Ollama)**
4. Go to **[2] Edit Configuration**
5. Set Base URL:

```
http://YOUR_PC_IP_ADDRESS:11434/v1
```

6. Set Model to your installed model (e.g., `llama3`)

---

## üõ†Ô∏è Troubleshooting

### **‚ùå ‚ÄúCommand not found‚Äù**

Run:

```bash
hash -r
```

Or restart Termux.

### **‚ùå Connection Errors**

* Check your API key in the menu
* Ensure internet is working
* If using remote models, verify credit/access
* For Ollama, ensure the server is reachable on your network

### **Config File Location**

```
~/.config/termux_ai_pro/config.json
```

---

## üìù License

This project is licensed under the **MIT License**.

